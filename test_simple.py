#!/usr/bin/env python3
"""
ç®€åŒ–çš„çˆ¬è™«ç³»ç»Ÿæµ‹è¯•è„šæœ¬
"""
import os
import sys
from pathlib import Path

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
project_root = Path(__file__).parent
sys.path.insert(0, str(project_root))


def test_directory_structure():
    """æµ‹è¯•ç›®å½•ç»“æ„"""
    print("æµ‹è¯•ç›®å½•ç»“æ„...")
    try:
        required_files = [
            "src/scrapy_project/__init__.py",
            "src/scrapy_project/spiders/__init__.py",
            "src/scrapy_project/spiders/1688_spider.py",
            "src/scrapy_project/items.py",
            "src/scrapy_project/settings.py",
            "src/scrapy_project/pipelines.py",
            "src/scrapy_project/middlewares.py",
            "src/scrapy_project/crawler.py",
            "src/database/models.py",
            "src/config.py",
            "scrapy.cfg"
        ]

        missing_files = []
        for file_path in required_files:
            full_path = project_root / file_path
            if not full_path.exists():
                missing_files.append(file_path)

        if missing_files:
            print(f"âœ— ç¼ºå°‘æ–‡ä»¶: {', '.join(missing_files)}")
            return False

        print("âœ“ æ‰€æœ‰å¿…éœ€æ–‡ä»¶éƒ½å­˜åœ¨")
        return True
    except Exception as e:
        print(f"âœ— ç›®å½•ç»“æ„æµ‹è¯•å¤±è´¥: {e}")
        return False


def test_spider_file_syntax():
    """æµ‹è¯•çˆ¬è™«æ–‡ä»¶è¯­æ³•"""
    print("æµ‹è¯•çˆ¬è™«æ–‡ä»¶è¯­æ³•...")
    try:
        spider_file = project_root / "src/scrapy_project/spiders/1688_spider.py"
        with open(spider_file, 'r', encoding='utf-8') as f:
            content = f.read()

        # æ£€æŸ¥å…³é”®ç±»å’Œæ–¹æ³•
        required_elements = [
            "class Product1688Spider",
            "def start_requests",
            "def parse_homepage",
            "def parse_search",
            "def parse_category",
            "def parse_product",
            "def _extract_title",
            "def _extract_price",
            "def _extract_image_urls"
        ]

        missing_elements = []
        for element in required_elements:
            if element not in content:
                missing_elements.append(element)

        if missing_elements:
            print(f"âœ— çˆ¬è™«æ–‡ä»¶ç¼ºå°‘å…ƒç´ : {', '.join(missing_elements)}")
            return False

        print("âœ“ çˆ¬è™«æ–‡ä»¶è¯­æ³•æ£€æŸ¥é€šè¿‡")
        return True
    except Exception as e:
        print(f"âœ— çˆ¬è™«æ–‡ä»¶è¯­æ³•æµ‹è¯•å¤±è´¥: {e}")
        return False


def test_pipeline_file_syntax():
    """æµ‹è¯•ç®¡é“æ–‡ä»¶è¯­æ³•"""
    print("æµ‹è¯•ç®¡é“æ–‡ä»¶è¯­æ³•...")
    try:
        pipeline_file = project_root / "src/scrapy_project/pipelines.py"
        with open(pipeline_file, 'r', encoding='utf-8') as f:
            content = f.read()

        # æ£€æŸ¥å…³é”®ç±»
        required_classes = [
            "class DataValidationPipeline",
            "class DatabasePipeline",
            "class ImageDownloadPipeline",
            "class DataCleaningPipeline",
            "class DuplicateFilterPipeline",
            "class StatsPipeline"
        ]

        missing_classes = []
        for class_name in required_classes:
            if class_name not in content:
                missing_classes.append(class_name)

        if missing_classes:
            print(f"âœ— ç®¡é“æ–‡ä»¶ç¼ºå°‘ç±»: {', '.join(missing_classes)}")
            return False

        print("âœ“ ç®¡é“æ–‡ä»¶è¯­æ³•æ£€æŸ¥é€šè¿‡")
        return True
    except Exception as e:
        print(f"âœ— ç®¡é“æ–‡ä»¶è¯­æ³•æµ‹è¯•å¤±è´¥: {e}")
        return False


def test_settings_file_syntax():
    """æµ‹è¯•è®¾ç½®æ–‡ä»¶è¯­æ³•"""
    print("æµ‹è¯•è®¾ç½®æ–‡ä»¶è¯­æ³•...")
    try:
        settings_file = project_root / "src/scrapy_project/settings.py"
        with open(settings_file, 'r', encoding='utf-8') as f:
            content = f.read()

        # æ£€æŸ¥å…³é”®è®¾ç½®
        required_settings = [
            "BOT_NAME",
            "SPIDER_MODULES",
            "USER_AGENT",
            "CONCURRENT_REQUESTS",
            "DOWNLOAD_DELAY",
            "ITEM_PIPELINES",
            "DOWNLOADER_MIDDLEWARES",
            "IMAGES_STORE"
        ]

        missing_settings = []
        for setting in required_settings:
            if setting not in content:
                missing_settings.append(setting)

        if missing_settings:
            print(f"âœ— è®¾ç½®æ–‡ä»¶ç¼ºå°‘é…ç½®: {', '.join(missing_settings)}")
            return False

        print("âœ“ è®¾ç½®æ–‡ä»¶è¯­æ³•æ£€æŸ¥é€šè¿‡")
        return True
    except Exception as e:
        print(f"âœ— è®¾ç½®æ–‡ä»¶è¯­æ³•æµ‹è¯•å¤±è´¥: {e}")
        return False


def test_middleware_file_syntax():
    """æµ‹è¯•ä¸­é—´ä»¶æ–‡ä»¶è¯­æ³•"""
    print("æµ‹è¯•ä¸­é—´ä»¶æ–‡ä»¶è¯­æ³•...")
    try:
        middleware_file = project_root / "src/scrapy_project/middlewares.py"
        with open(middleware_file, 'r', encoding='utf-8') as f:
            content = f.read()

        # æ£€æŸ¥å…³é”®ä¸­é—´ä»¶ç±»
        required_middlewares = [
            "class UserAgentMiddleware",
            "class ProxyMiddleware",
            "class RateLimitMiddleware",
            "class RetryMiddlewareWithBackoff",
            "class HeaderMiddleware",
            "class AntiDetectionMiddleware"
        ]

        missing_middlewares = []
        for middleware in required_middlewares:
            if middleware not in content:
                missing_middlewares.append(middleware)

        if missing_middlewares:
            print(f"âœ— ä¸­é—´ä»¶æ–‡ä»¶ç¼ºå°‘ç±»: {', '.join(missing_middlewares)}")
            return False

        print("âœ“ ä¸­é—´ä»¶æ–‡ä»¶è¯­æ³•æ£€æŸ¥é€šè¿‡")
        return True
    except Exception as e:
        print(f"âœ— ä¸­é—´ä»¶æ–‡ä»¶è¯­æ³•æµ‹è¯•å¤±è´¥: {e}")
        return False


def test_database_models_syntax():
    """æµ‹è¯•æ•°æ®åº“æ¨¡å‹è¯­æ³•"""
    print("æµ‹è¯•æ•°æ®åº“æ¨¡å‹è¯­æ³•...")
    try:
        models_file = project_root / "src/database/models.py"
        with open(models_file, 'r', encoding='utf-8') as f:
            content = f.read()

        # æ£€æŸ¥å…³é”®æ¨¡å‹
        required_models = [
            "class Product",
            "class ProductImage",
            "class SyncLog",
            "class SyncTask"
        ]

        missing_models = []
        for model in required_models:
            if model not in content:
                missing_models.append(model)

        if missing_models:
            print(f"âœ— æ•°æ®åº“æ¨¡å‹ç¼ºå°‘ç±»: {', '.join(missing_models)}")
            return False

        print("âœ“ æ•°æ®åº“æ¨¡å‹è¯­æ³•æ£€æŸ¥é€šè¿‡")
        return True
    except Exception as e:
        print(f"âœ— æ•°æ®åº“æ¨¡å‹è¯­æ³•æµ‹è¯•å¤±è´¥: {e}")
        return False


def test_config_file_syntax():
    """æµ‹è¯•é…ç½®æ–‡ä»¶è¯­æ³•"""
    print("æµ‹è¯•é…ç½®æ–‡ä»¶è¯­æ³•...")
    try:
        config_file = project_root / "src/config.py"
        with open(config_file, 'r', encoding='utf-8') as f:
            content = f.read()

        # æ£€æŸ¥å…³é”®é…ç½®
        required_configs = [
            "class Settings",
            "name",
            "database_url",
            "base_url",
            "scrapy_download_delay",
            "scrapy_concurrent_requests"
        ]

        missing_configs = []
        for config in required_configs:
            if config not in content:
                missing_configs.append(config)

        if missing_configs:
            print(f"âœ— é…ç½®æ–‡ä»¶ç¼ºå°‘é…ç½®: {', '.join(missing_configs)}")
            return False

        print("âœ“ é…ç½®æ–‡ä»¶è¯­æ³•æ£€æŸ¥é€šè¿‡")
        return True
    except Exception as e:
        print(f"âœ— é…ç½®æ–‡ä»¶è¯­æ³•æµ‹è¯•å¤±è´¥: {e}")
        return False


def test_scrapy_cfg():
    """æµ‹è¯•Scrapyé…ç½®æ–‡ä»¶"""
    print("æµ‹è¯•Scrapyé…ç½®æ–‡ä»¶...")
    try:
        scrapy_cfg = project_root / "scrapy.cfg"
        with open(scrapy_cfg, 'r', encoding='utf-8') as f:
            content = f.read()

        if "[settings]" not in content:
            print("âœ— scrapy.cfgç¼ºå°‘[settings]éƒ¨åˆ†")
            return False

        if "default = src.scrapy_project.settings" not in content:
            print("âœ— scrapy.cfgç¼ºå°‘é»˜è®¤è®¾ç½®")
            return False

        print("âœ“ Scrapyé…ç½®æ–‡ä»¶æ£€æŸ¥é€šè¿‡")
        return True
    except Exception as e:
        print(f"âœ— Scrapyé…ç½®æ–‡ä»¶æµ‹è¯•å¤±è´¥: {e}")
        return False


def run_simple_tests():
    """è¿è¡Œç®€åŒ–æµ‹è¯•"""
    print("=" * 60)
    print("å¼€å§‹è¿è¡Œ1688syncçˆ¬è™«ç³»ç»Ÿç®€åŒ–æµ‹è¯•")
    print("=" * 60)

    tests = [
        test_directory_structure,
        test_spider_file_syntax,
        test_pipeline_file_syntax,
        test_settings_file_syntax,
        test_middleware_file_syntax,
        test_database_models_syntax,
        test_config_file_syntax,
        test_scrapy_cfg,
    ]

    passed = 0
    failed = 0

    for test in tests:
        try:
            if test():
                passed += 1
            else:
                failed += 1
        except Exception as e:
            print(f"âœ— æµ‹è¯•å¼‚å¸¸: {test.__name__} - {e}")
            failed += 1
        print()

    print("=" * 60)
    print(f"æµ‹è¯•å®Œæˆ - é€šè¿‡: {passed}, å¤±è´¥: {failed}")
    print("=" * 60)

    if failed == 0:
        print("ğŸ‰ æ‰€æœ‰åŸºç¡€æµ‹è¯•é€šè¿‡ï¼çˆ¬è™«ç³»ç»Ÿç»“æ„å®Œæ•´ã€‚")
        print("\nä¸‹ä¸€æ­¥æ“ä½œ:")
        print("1. å®‰è£…ä¾èµ–: pip install -r requirements.txt")
        print("2. é…ç½®æ•°æ®åº“: ç¼–è¾‘.envæ–‡ä»¶")
        print("3. è¿è¡Œçˆ¬è™«: python src/scrapy_project/crawler.py --keyword 'æ‰‹æœº'")
        return True
    else:
        print("âŒ éƒ¨åˆ†æµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥é—®é¢˜ã€‚")
        return False


if __name__ == '__main__':
    success = run_simple_tests()
    sys.exit(0 if success else 1)