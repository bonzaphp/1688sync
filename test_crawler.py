#!/usr/bin/env python3
"""
çˆ¬è™«ç³»ç»Ÿæµ‹è¯•è„šæœ¬
"""
import os
import sys
import json
from pathlib import Path
from unittest.mock import Mock, patch

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
project_root = Path(__file__).parent
sys.path.insert(0, str(project_root))

try:
    from src.config import settings
    CONFIG_AVAILABLE = True
except ImportError as e:
    print(f"é…ç½®æ¨¡å—å¯¼å…¥å¤±è´¥: {e}")
    CONFIG_AVAILABLE = False

try:
    from src.scrapy_project.spiders._1688_spider import Product1688Spider
    from src.scrapy_project.items import ProductItem
    from src.scrapy_project.pipelines import (
        DataValidationPipeline,
        DataCleaningPipeline,
        DuplicateFilterPipeline,
        ImageDownloadPipeline
    )
    SCRAPY_AVAILABLE = True
except ImportError as e:
    print(f"Scrapyæ¨¡å—å¯¼å…¥å¤±è´¥: {e}")
    SCRAPY_AVAILABLE = False


def test_spider_initialization():
    """æµ‹è¯•çˆ¬è™«åˆå§‹åŒ–"""
    print("æµ‹è¯•çˆ¬è™«åˆå§‹åŒ–...")
    if not SCRAPY_AVAILABLE:
        print("âš  Scrapyæ¨¡å—ä¸å¯ç”¨ï¼Œè·³è¿‡æµ‹è¯•")
        return True

    try:
        spider = Product1688Spider()
        assert spider.name == "1688_products"
        assert "1688.com" in spider.allowed_domains
        print("âœ“ çˆ¬è™«åˆå§‹åŒ–æˆåŠŸ")
        return True
    except Exception as e:
        print(f"âœ— çˆ¬è™«åˆå§‹åŒ–å¤±è´¥: {e}")
        return False


def test_spider_with_keyword():
    """æµ‹è¯•å…³é”®è¯æœç´¢çˆ¬è™«"""
    print("æµ‹è¯•å…³é”®è¯æœç´¢çˆ¬è™«...")
    try:
        spider = Product1688Spider(keyword="æ‰‹æœº")
        assert spider.keyword == "æ‰‹æœº"
        print("âœ“ å…³é”®è¯çˆ¬è™«åˆå§‹åŒ–æˆåŠŸ")
        return True
    except Exception as e:
        print(f"âœ— å…³é”®è¯çˆ¬è™«åˆå§‹åŒ–å¤±è´¥: {e}")
        return False


def test_spider_with_category():
    """æµ‹è¯•åˆ†ç±»çˆ¬è™«"""
    print("æµ‹è¯•åˆ†ç±»çˆ¬è™«...")
    try:
        spider = Product1688Spider(category="ç”µå­äº§å“")
        assert spider.category == "ç”µå­äº§å“"
        print("âœ“ åˆ†ç±»çˆ¬è™«åˆå§‹åŒ–æˆåŠŸ")
        return True
    except Exception as e:
        print(f"âœ— åˆ†ç±»çˆ¬è™«åˆå§‹åŒ–å¤±è´¥: {e}")
        return False


def test_item_creation():
    """æµ‹è¯•å•†å“é¡¹åˆ›å»º"""
    print("æµ‹è¯•å•†å“é¡¹åˆ›å»º...")
    try:
        item = ProductItem()
        item['title'] = "æµ‹è¯•å•†å“"
        item['price'] = 99.99
        item['product_id'] = "test_001"
        item['source_url'] = "https://example.com/product/001"

        assert item['title'] == "æµ‹è¯•å•†å“"
        assert item['price'] == 99.99
        assert item['product_id'] == "test_001"
        print("âœ“ å•†å“é¡¹åˆ›å»ºæˆåŠŸ")
        return True
    except Exception as e:
        print(f"âœ— å•†å“é¡¹åˆ›å»ºå¤±è´¥: {e}")
        return False


def test_data_validation_pipeline():
    """æµ‹è¯•æ•°æ®éªŒè¯ç®¡é“"""
    print("æµ‹è¯•æ•°æ®éªŒè¯ç®¡é“...")
    try:
        pipeline = DataValidationPipeline()

        # åˆ›å»ºæ¨¡æ‹Ÿçˆ¬è™«
        spider = Mock()
        spider.logger = Mock()

        # æµ‹è¯•æœ‰æ•ˆæ•°æ®
        item = ProductItem()
        item['title'] = "æµ‹è¯•å•†å“"
        item['price'] = 99.99

        result = pipeline.process_item(item, spider)
        assert 'crawl_time' in result
        print("âœ“ æœ‰æ•ˆæ•°æ®éªŒè¯æˆåŠŸ")

        # æµ‹è¯•æ— æ•ˆæ•°æ®ï¼ˆç¼ºå°‘æ ‡é¢˜ï¼‰
        invalid_item = ProductItem()
        invalid_item['price'] = 99.99

        try:
            pipeline.process_item(invalid_item, spider)
            print("âœ— æ— æ•ˆæ•°æ®éªŒè¯å¤±è´¥ï¼ˆåº”è¯¥æŠ›å‡ºå¼‚å¸¸ï¼‰")
            return False
        except:
            print("âœ“ æ— æ•ˆæ•°æ®éªŒè¯æˆåŠŸï¼ˆæ­£ç¡®æŠ›å‡ºå¼‚å¸¸ï¼‰")

        return True
    except Exception as e:
        print(f"âœ— æ•°æ®éªŒè¯ç®¡é“æµ‹è¯•å¤±è´¥: {e}")
        return False


def test_data_cleaning_pipeline():
    """æµ‹è¯•æ•°æ®æ¸…ç†ç®¡é“"""
    print("æµ‹è¯•æ•°æ®æ¸…ç†ç®¡é“...")
    try:
        pipeline = DataCleaningPipeline()
        spider = Mock()

        # æµ‹è¯•æ–‡æœ¬æ¸…ç†
        item = ProductItem()
        item['title'] = "  æµ‹è¯•å•†å“  \n\t  "
        item['description'] = "è¿™æ˜¯ä¸€ä¸ªæµ‹è¯•æè¿°" * 100  # å¾ˆé•¿çš„æè¿°
        item['tags'] = ["æ ‡ç­¾1", "æ ‡ç­¾2", "æ ‡ç­¾1", ""]  # é‡å¤å’Œç©ºæ ‡ç­¾

        result = pipeline.process_item(item, spider)

        assert result['title'] == "æµ‹è¯•å•†å“"
        assert len(result['description']) <= 2003  # 2000 + "..."
        assert len(set(result['tags'])) == len(result['tags'])  # æ— é‡å¤
        assert "" not in result['tags']  # æ— ç©ºæ ‡ç­¾

        print("âœ“ æ•°æ®æ¸…ç†æˆåŠŸ")
        return True
    except Exception as e:
        print(f"âœ— æ•°æ®æ¸…ç†ç®¡é“æµ‹è¯•å¤±è´¥: {e}")
        return False


def test_duplicate_filter_pipeline():
    """æµ‹è¯•é‡å¤è¿‡æ»¤ç®¡é“"""
    print("æµ‹è¯•é‡å¤è¿‡æ»¤ç®¡é“...")
    try:
        pipeline = DuplicateFilterPipeline()
        spider = Mock()
        spider.logger = Mock()

        # ç¬¬ä¸€ä¸ªå•†å“åº”è¯¥é€šè¿‡
        item1 = ProductItem()
        item1['product_id'] = "test_001"
        item1['title'] = "æµ‹è¯•å•†å“1"
        item1['price'] = 99.99

        result1 = pipeline.process_item(item1, spider)
        assert result1 == item1

        # ç›¸åŒå•†å“åº”è¯¥è¢«è¿‡æ»¤
        item2 = ProductItem()
        item2['product_id'] = "test_001"
        item2['title'] = "æµ‹è¯•å•†å“1"
        item2['price'] = 99.99

        try:
            pipeline.process_item(item2, spider)
            print("âœ— é‡å¤è¿‡æ»¤å¤±è´¥ï¼ˆåº”è¯¥æŠ›å‡ºå¼‚å¸¸ï¼‰")
            return False
        except:
            print("âœ“ é‡å¤è¿‡æ»¤æˆåŠŸï¼ˆæ­£ç¡®æŠ›å‡ºå¼‚å¸¸ï¼‰")

        return True
    except Exception as e:
        print(f"âœ— é‡å¤è¿‡æ»¤ç®¡é“æµ‹è¯•å¤±è´¥: {e}")
        return False


def test_image_download_pipeline():
    """æµ‹è¯•å›¾ç‰‡ä¸‹è½½ç®¡é“"""
    print("æµ‹è¯•å›¾ç‰‡ä¸‹è½½ç®¡é“...")
    try:
        pipeline = ImageDownloadPipeline(store_uri="./test_images")
        spider = Mock()
        spider.logger = Mock()

        # æµ‹è¯•æœ‰æ•ˆå›¾ç‰‡URL
        item = ProductItem()
        item['product_id'] = "test_001"
        item['image_urls'] = [
            "https://example.com/image1.jpg",
            "https://example.com/image2.png",
            "invalid_url",  # æ— æ•ˆURLåº”è¯¥è¢«è¿‡æ»¤
            "/relative/path.jpg",  # ç›¸å¯¹è·¯å¾„åº”è¯¥è¢«è¿‡æ»¤
        ]

        requests = pipeline.get_media_requests(item, {})
        assert len(requests) == 2  # åªæœ‰ä¸¤ä¸ªæœ‰æ•ˆURL
        print("âœ“ å›¾ç‰‡URLè¿‡æ»¤æˆåŠŸ")
        return True
    except Exception as e:
        print(f"âœ— å›¾ç‰‡ä¸‹è½½ç®¡é“æµ‹è¯•å¤±è´¥: {e}")
        return False


def test_configuration():
    """æµ‹è¯•é…ç½®"""
    print("æµ‹è¯•é…ç½®...")
    try:
        assert settings.name == "1688sync"
        assert settings.base_url == "https://www.1688.com"
        assert settings.scrapy_download_delay >= 0
        assert settings.scrapy_concurrent_requests > 0
        print("âœ“ é…ç½®éªŒè¯æˆåŠŸ")
        return True
    except Exception as e:
        print(f"âœ— é…ç½®éªŒè¯å¤±è´¥: {e}")
        return False


def test_directory_structure():
    """æµ‹è¯•ç›®å½•ç»“æ„"""
    print("æµ‹è¯•ç›®å½•ç»“æ„...")
    try:
        required_dirs = [
            "src/scrapy_project",
            "src/scrapy_project/spiders",
            "src/database",
            "src/config.py"
        ]

        for path in required_dirs:
            full_path = project_root / path
            if path.endswith('.py'):
                assert full_path.is_file(), f"ç¼ºå°‘æ–‡ä»¶: {path}"
            else:
                assert full_path.is_dir(), f"ç¼ºå°‘ç›®å½•: {path}"

        print("âœ“ ç›®å½•ç»“æ„éªŒè¯æˆåŠŸ")
        return True
    except Exception as e:
        print(f"âœ— ç›®å½•ç»“æ„éªŒè¯å¤±è´¥: {e}")
        return False


def run_all_tests():
    """è¿è¡Œæ‰€æœ‰æµ‹è¯•"""
    print("=" * 60)
    print("å¼€å§‹è¿è¡Œ1688syncçˆ¬è™«ç³»ç»Ÿæµ‹è¯•")
    print("=" * 60)

    tests = [
        test_configuration,
        test_directory_structure,
        test_spider_initialization,
        test_spider_with_keyword,
        test_spider_with_category,
        test_item_creation,
        test_data_validation_pipeline,
        test_data_cleaning_pipeline,
        test_duplicate_filter_pipeline,
        test_image_download_pipeline,
    ]

    passed = 0
    failed = 0

    for test in tests:
        try:
            if test():
                passed += 1
            else:
                failed += 1
        except Exception as e:
            print(f"âœ— æµ‹è¯•å¼‚å¸¸: {test.__name__} - {e}")
            failed += 1
        print()

    print("=" * 60)
    print(f"æµ‹è¯•å®Œæˆ - é€šè¿‡: {passed}, å¤±è´¥: {failed}")
    print("=" * 60)

    if failed == 0:
        print("ğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼çˆ¬è™«ç³»ç»Ÿå‡†å¤‡å°±ç»ªã€‚")
        return True
    else:
        print("âŒ éƒ¨åˆ†æµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥é—®é¢˜ã€‚")
        return False


if __name__ == '__main__':
    success = run_all_tests()
    sys.exit(0 if success else 1)