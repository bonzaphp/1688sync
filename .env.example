# 1688sync API 环境配置示例
# 复制此文件为 .env 并修改相应配置

# 基础配置
DEBUG=false
LOG_LEVEL=INFO

# 数据库配置
DATABASE_URL=mysql+pymysql://user:password@localhost:3306/1688sync

# Redis配置
REDIS_URL=redis://localhost:6379/0

# API服务配置
API_HOST=0.0.0.0
API_PORT=8000
API_DEBUG=false

# Scrapy配置
SCRAPY_USER_AGENT=1688sync-bot/1.0
SCRAPY_CONCURRENT_REQUESTS=16
SCRAPY_DOWNLOAD_DELAY=1.0
SCRAPY_RANDOMIZE_DOWNLOAD_DELAY=true

# Celery配置
CELERY_BROKER_URL=redis://localhost:6379/0
CELERY_RESULT_BACKEND=redis://localhost:6379/0

# 安全配置
SECRET_KEY=your-super-secret-key-change-this-in-production
ALGORITHM=HS256

# 文件存储配置
DATA_DIR=./data
IMAGE_DIR=./data/images
LOG_FILE=logs/1688sync.log

# 存储配置
STORAGE_PATH=./images
MAX_FILE_SIZE=10485760
CDN_BASE_URL=
CDN_ENABLED=false

# Redis配置
CELERY_BROKER_URL=redis://localhost:6379/0
CELERY_RESULT_BACKEND=redis://localhost:6379/1
REDIS_URL=redis://localhost:6379/0
CACHE_TTL=3600

# Celery配置
CELERY_WORKER_CONCURRENCY=4
CELERY_WORKER_PREFETCH_MULTIPLIER=1
CELERY_TASK_TIME_LIMIT=1800
CELERY_TASK_SOFT_TIME_LIMIT=1500
CELERY_WORKER_MAX_TASKS_PER_CHILD=1000
CELERY_WORKER_DISABLE_RATE_LIMITS=false

# 队列配置
CELERY_DEFAULT_QUEUE=default
CELERY_QUEUES=default,crawler,image_processing,data_sync,batch_processing
CELERY_ROUTES_ENABLED=true

# 监控配置
CELERY_SEND_TASK_EVENTS=true
CELERY_TASK_TRACK_STARTED=true
CELERY_TASK_SEND_SENT_EVENT=true

# 检查点配置
CHECKPOINT_DIR=./checkpoints
CHECKPOINT_MAX_PER_TASK=100
CHECKPOINT_AUTO_SAVE=true

# 恢复配置
RECOVERY_MAX_RETRIES=3
RECOVERY_RETRY_DELAY=60
RECOVERY_BACKOFF_FACTOR=2.0
RECOVERY_MAX_RETRY_DELAY=3600

# 并发配置
MAX_CONCURRENT_REQUESTS=100
REQUEST_TIMEOUT=30

# 监控配置（可选）
# SENTRY_DSN=https://your-sentry-dsn
METRICS_ENABLED=false

# 数据同步配置
BATCH_SIZE=1000
SYNC_INTERVAL=300
RETRY_ATTEMPTS=3
RETRY_DELAY=5